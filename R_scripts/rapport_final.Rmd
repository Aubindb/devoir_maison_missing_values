---
title: "Devoir ACP et valeurs manquantes, Novembre 2018"
author: "Aubin de Belleroche, Camille Moatti"
date: "01 Novembre 2018"
output:
  pdf_document:
    toc: yes
    toc_depth: '3'
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Les données issues du monde réel sont souvent moins faciles à manipuler que celles formatées pour les salles de classe.  
L'analyste doit fréquemment remanier les données afin d'obtenir un enregistrement par ligne et une variable par colonne (*tidy data*) ainsi que reformater les données (paramètres régionaux, formats des dates, codage des catégories...). 
Très souvent, les jeux de données contiennent également des valeurs manquantes. Cela peut-être dû à une multitude de facteurs :

* défaillance matérielle (capteur en panne par exemple)
* nouvelle variable apparue à une certaine date (valeurs manquantes pour les dates antérieures)
* sondage  auxquel les sondés n'ont répondu que partiellement
* individu faisant parti d'une cohorte n'étant plus en mesure de répondre...  

A chaque fois, l'analyste devra déterminer quels sont les raisons de la présence de ces valeurs manquantes avant de trouver une solution pour y remédier.  
Il n'existe malheureusement pas de manière unique de traiter les valeurs manquantes. Plusieurs techniques pourront être essayés afin de trouver la meilleure solution dans un cas donné. Le but de l'imputation est donc de compléter un jeu de données sans changer la structure des données réelles. En effet, une mauvaise imputation ou l'abandon de certaines observations peut conduire à des analyses biasées.

### Présentation du jeu et analyse exploratoire

Nous avons choisi d'analyser un jeu qui provient de la banque mondiale. L'institution financière internationale, dont le rôle est d'accorder des prêts afin d'encourager le développement, dispose d'un site permettant de requêter des données sur l'ensemble des pays. Nous avons choisi d'analyser les indicateurs les plus populaires (*Popular Indicators*). Le détail des variables ainsi que leurs sources sont disponibles dans le fichier `des.xlsx` à la racine du projet.  

Le but final de notre étude sera d'implémenter un modèle pour expliquer et prévoir le nombre d'enfants par femme dans un pays donné.

Nous chargeons les *packages* nécessaires à l'analyse :
  
> Code R masqué.

```{r init, include=F, warning=FALSE, results='hide'}
library("tidyverse")
library("magrittr")

library("FactoMineR")
library("factoextra") #http://www.sthda.com/english/rpkgs/factoextra/

library("missMDA")
library("mice")
library("randomForest")
library("FactoInvestigate")

library("VIM")

library(UpSetR)
library(naniar)
```

Après avoir chargé les données nous observons la répartition des valeurs manquantes en leur sein.

```{r}
raw_data2 <- readxl::read_xlsx("../data/Popular Indicators.xlsx", na="..") %>% filter(Time==2010)
raw_data2 %>%
  summarise_all(funs(sum(is.na(.)))) / nrow(raw_data2) * 100 -> missing_values_pct
gg_miss_var(raw_data2, show_pct = TRUE)
```

Nous remarquons qu'un certain nombre de variables ont un pourcentage de valeurs manquantes très élevé. Etant donné le peu d'individus présents dans l'échantillon, nous avons considéré que les variables présentant un taux de valeurs manquantes supérieur à 20% ne présentaient pas assez de données pour imputer sans risque d'abimer le modèle. Les colonnes correspondantes ont donc été supprimées. 

Nous abandonnons également les enregistrements sur lesquels notre *target variable* n'a pas de valeur. La variable `data clean` contient donc un `Tible` qui sera utilisé comme point de départ des imputations.

```{r}
missing_values_pct <- missing_values_pct %>% gather() %>% arrange(-value)
inf_20_pct<-missing_values_pct %>% filter(value<=20)
data_limited_missing <- raw_data2 %>% select(inf_20_pct$key)
data_clean <- data_limited_missing %>%
  drop_na(`Fertility rate, total (births per woman) [SP.DYN.TFRT.IN]`)
```

Nous avons également choisi de supprimer les colonnes présentant des mesures de PIB par pays. En effet, nous disposons également du PIB par individu et de la population pour chaque pays, le PIB global n'apporte donc pas plus d'information.

```{r}
data_clean %<>% select(-c(`GNI, PPP (current international $) [NY.GNP.MKTP.PP.CD]`,
                          `GNI, Atlas method (current US$) [NY.GNP.ATLS.CD]`,
                          `GDP (current US$) [NY.GDP.MKTP.CD]`))
```

Afin de faciliter la lecture dans la suite de notre analyse, nous renomons les différentes colonnes par des lettres et conservons la correspondance dans un dictionnaire.

```{r}
saved_names <- names(data_clean)
LETTERS702 <- c(LETTERS, sapply(LETTERS, function(x) paste0(x, LETTERS)))
names(data_clean) <- LETTERS702[1:dim(data_clean)[2]]

letters_dict <- saved_names
names(letters_dict) <- LETTERS702[1:dim(data_clean)[2]]
```

La méthode de l'imputation multiple sera privilégiée tout au long de ce devoir afin de pouvoir estimer l'incertitude associée à notre imputation.  

## Imputation des données manquantes et choix du modèle
### Détermination du mécanisme

Afin de choisir correctement la méthode d'imputation des données manquantes, il convient d'en déterminer le mécanisme. On considère 3 cas possibles (Little & Rubin) :
  
* MCAR (missing completely at random) si probabilité d’absence est la même pour toutes les observations, c'est à dire qu'elle ne dépend que de paramètres extérieurs;
* MAR (missing at random) lorsque la probabilité d’absence est liée à une ou plusieurs autres données observées;
* MNAR (Missing not at random) si les données observées ne suffisent pas à expliquer les données manquantes, c'est à dire que ces dernières dépendent également des données manquantes.

Afin d'analyser la répartition des valeurs manquantes, nous réalisons le graphique suivant à l'aide du package VIM

```{r}
VIM::aggr(data_clean)
```

Nous en déduisons qu'il ne semble pas exister de schéma spécifique de répartion de nos données manquantes. En effet, aucune répartition de ces dernières en fonction des variables n'apparaît avec une fréquence sensiblement supérieure aux autres. En revanche la répartition des valeurs manquantes selon les variables est très inégale, le cas le cas MCAR semble donc exclu dans notre échantillon.

La distinction entre les cas MAR et MNAR n'est ici pas possible sans connaître la façon dont les données ont été collectées. Par défaut nous supposerons un mécanisme MAR et vérifierons la robustesse de ce choix à postériori.


### Imputation et ACP

Dans un premier temps, nous implémentons l'algorithme de l'ACP itératif afin de réaliser une imputation multiple. 
L'explication détaillée de l'algorithme est disponible sur [YouTube](https://www.youtube.com/watch?v=OOM8_FH6_8o).

Le *chunk* suivant permet de régler quelques détails, notamment la conversion en `data.frame` base R et le centrage réduction des données.   
Nous enlevons la variable cible afin d'éviter le **surapprentissage**.

```{r}
data_clean_numeric <- data_clean %>%
  select(which(sapply(.,is.numeric))) %>%
  as.data.frame(.)

data_clean_numeric <- scale(data_clean_numeric) %>% as.data.frame(.)

target <- data_clean_numeric$Q
data_clean_numeric %<>% select(-Q)
```

Puis nous utilisons l'algorithme avec 10 *resampling* via *Parametric Bootstrap (Josse, J., Husson, F. (2010))*:

```{r}
nbdim <- estim_ncpPCA(data_clean_numeric)
res.comp <- MIPCA(data_clean_numeric, ncp = nbdim$ncp, scale=TRUE, nboot = 10)
imp<-prelim(res.comp, data_clean_numeric)
```

La fonction `prelim` permet d'obtenir un objet de type `mids` et d'utiliser les capacités graphiques du package `mice`.
Nous commençons par les graphiques prévus par MissMDA :

```{r, fig.keep='all',fig.show='hold', error=F}
plot(res.comp)
```

Les graphiques montrent que les axes sont stables entre les n imputations. De plus, les valeurs imputées ont une variabilité plutôt limitée. Nous pouvons noter que les variables A et C sont mal représentées.

Puis nous utilisons les fonctions `densityplot` et `stripplot` du *package* `mice` :

```{r}
densityplot(imp)
stripplot(imp, pch = 20, cex = 1.2)
```

Le `stripplot` permet de bien visualiser la stabilité des valeurs imputées (points rouges) d'une imputation à l'autre. En abscisse, les n imputations sont représentées. En ordonnées, nous avons les valeurs imputées. Pour s'assurer de la robustesse de la procédure d'imputation, il faut que les points rouges soient similaires tout au long de l'axe des abscisses. Pour cette raison, les valeurs imputées sur les variables P et U ne sont pas satisfaisantes. Cependant, nous ne les enlevons pas à ce stade.  
  
Afin de continuer vers la modélisation, nous choisissons dans un premier temps de réduire le nombre de dimensions :

```{r}
data_imputed <- res.comp[["res.imputePCA"]]

res<-PCA(data_imputed, graph = F)
```

Même si la première dimension domine largement les autres, il semble opportun de garder quatre dimensions supplémentaires (72% de variance conservée), en effet la première ne modélise que 31,1% de l'inertie de notre jeu de donnée. On constate également un coude après la cinquième dimension, ce qui nous conforte dans notre choix.

```{r, fig.show = 'hold', out.width = '50%'}
fviz_screeplot(res, addlabels = TRUE, ylim = c(0, 35))

fviz_pca_var(res, col.var="contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE # Avoid text overlapping
             )
```
  
Nous notons que, hormis A et C, les variables contribuent toutes correctement aux premier plan, certaines bien plus que d'autres. Il est apparent que M, N et D contribuent à l'axe 1 très négativement et qu'à l'inverse T, J, P, F, U et K ont un impact très positif. Ces variables n'ont en revanche que peu d'impact sur l'axe 2 à l'inverse de I, L et H qui contribuent négativent à ce dernier et positivement au premier. Enfin un le groupe restant a une plus faible contribution positive à l'axe 2 tout en étant réparti sur l'axe 1.

```{r, fig.show = 'hold', out.width = '50%'}
fviz_contrib(res, choice = "var", axes = 1, top = 10)

fviz_contrib(res, choice = "var", axes = 2, top = 10)
```

La fonction `Investigate(res)` du package `FactoInvestigate` permet de générer un rapport automatisé sur notre ACP. Cette analyse peut servir de point de départ afin d'affiner l'interprétation. 
(A COMPLETER)

Nous pouvons d'ores et déjà visualiser la fertilitité sur les deux premiers axes de notre ACP. Pour ce faire, nous créons trois catégorie à partir de la variable continue cible. Ces trois catégories peuvent être interprétées comme des niveaux du nombre d'enfants par femme (élevé, moyen et faible). Pour ce faire, nous utilisons la fonction `cut` :

```{r}
fviz_pca_ind(res,
             label = "none",
             habillage = cut(target,3),
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE)
```
  
Avec seulement deux dimensions, nous observons qu'un point ayant une valeur positive sur la première dimension appartient presque toujours à la première catégorie (faible fertilité).  
Les deux autres catégories, bien que plus proches, permettent d'observer que les pays où les femmes ont beaucoup d'enfants tendent à avoir une valeur très négative sur la première dimension.  
Le visualisation de la seconde dimension par rapport à la troisième est plus difficile à interpréter de prime abord :

```{r}
fviz_pca_ind(res,
             axes=c(2,3),
             label = "none",
             habillage = cut(target,3),
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE)
```

Notre première modélisation, effectuée après imputation des valeurs manquantes et réduction de la dimension à cinq axes, permet d'obtenir un R ajusté de 78%.

```{r}
ind_coord <- res[["ind"]][["coord"]] %>% as_tibble()
ind_coord_target <- ind_coord %>% mutate(target = target)
fit <- lm(target~.-1, ind_coord_target)
summary(fit)
```

### Imputation et Algorithme Mice

L'algorithme utilisé dans le package Mice (**M**ultivariate **I**mputation by **C**hained **E**quations) a été dévelopé par Stef van Buuren. Tout comme l'algorithme implémenté dans MissMDA, dévelopé par François Husson, Mice utilise une approche itérative afin d'imputer les valeurs manquantes. L'approche multiple permet de mesurer l'incertitude quant aux valeurs imputées.  
Afin d'effectuer notre analyse, nous allons utiliser la fonction `mice()` en variant les méthodes d'imputation.  
`mice` est une méthode de Monte Carlo par chaines de Markov qui utilise la structure des corrélations pour trouver des valeurs plausibles sur les jeux incomplets.  
Nous allons essayer trois méthodes :
  
* *Predictive Mean Matching (Rubin 1986, Little 1988)* : Cette méthode est la méthode par défaut de la fonction `mice()`. Cependant, aucune théorie mathématique n'a prouvé la pertinence de cette méthode. Toutefois, cette méthode permet d'imputer avec des valeurs empruntées aux autres observations. Par exemple, sur une colonne d'entiers, *pmm* imputera des entiers. Les valeurs imputées seront contenues entre la borne minimum et maximum de la variable. Ces qualités ont rendu cette méthode assez populaire. [Cet article](https://statisticalhorizons.com/predictive-mean-matching) explique l'algorithme en détail ainsi que ses limites.
* *Linear Regression Ignoring Model Error* : Cette seconde méthode utilise un modèle linéaire afin d'estimer les valeurs manquantes. Cependant, l'algorithme ajoute un bruit gaussien à la prédiction afin d'eviter l'*overfitting*. Mice propose d'autres algorithmes d'imputations s'appuyant sur le modèle linéaire gaussien. [Cette page](https://stefvanbuuren.name/fimd/sec-linearnormal.html) les explique en détail. Nous utiliserons donc `norm.nob`.
* *Random Forest* : Cet algorithme ensembliste est une amélioration de l'arbre de décision simple. Il est utilisé dans le cadre de l'apprentissage statistique afin de réduire la tendance à l'*overfitting* des arbres. Tout comme les arbres, il peut être utilisé pour prédire des variables continues. Ces méthodes sont robustes aux *outliers*, gèrent la multicollinéarité et les distributions assymétriques. Cela est appréciable dans le cadre de l'imputation.
[Cette page](https://stefvanbuuren.name/fimd/sec-cart.html) peut être consultée pour plus de détails.

Tout comme précédemment, nous remanions légèrement notre tableau afin d'assurer sa compatibilité avec `mice`. Grâce à `predictorMatrix`, nous pouvons empêcher la variable `Q` d'être utilisée lors de l'imputation :

```{r}
data_clean_numeric_mice <- data_clean %>% 
  select(which(sapply(.,is.numeric)))
data_clean_numeric_mice <- scale(data_clean_numeric_mice) %>%
  as.data.frame(.)

imp <- mice(data_clean_numeric_mice, print = FALSE)
pred <- imp$predictorMatrix
pred[, "Q"] <- 0
```

Nous imputons avec les trois méthodes décrites précédemment. Dix imputations sont réalisées pour chaque méthode :

```{r, results='hide'}
imputed_pmm = mice(data_clean_numeric_mice, pred = pred, method="pmm", m=10)

imputed_normnob = mice(data_clean_numeric_mice, pred = pred, method="norm.nob", m=10)

imputed_rf = mice(data_clean_numeric_mice, pred = pred,method="rf", m=10)
```

Nous cherchons ensuite à déterminer les variables à conserver dans nos 3 cas à l'aide d'une méthode pas à pas. Pour réaliser cela, nous suivons le mode opératoire décris par Brand (1999) : nous appliquons une méthode pas à pas sur chaque table imputée séparement, puis nous comptons le nombre d'apparition de chaque variable dans les 10 modèles ainsi créés pour ne conserver que celles qui apparaissent dans plus de la moitié dans un "supermodèle" final.

Ces opérations seront réalisées à l'aide des fonctions suivantes

```{r}
step_on_mice <- function (mice_object, direction = "both") {
  fit <- with(data = mice_object, exp = lm(Q ~ A+B+C+D+E+F+G+H+I+J+
                                             K+L+M+O+P+R+S+T+U+V+AA))
  len <- length(fit$analyses)
  all_kept_var <- vector()
  for (i in 1:len) {
    mod_step <- step(fit$analyses[[i]], direction = direction,trace=0)
    kept_var <- names(mod_step[["coefficients"]])
    all_kept_var <- c(all_kept_var, kept_var)
  }
  table(all_kept_var)
}

make_linear_model <- function(mice_object, step_on_mice_res, threshold = 5, intercept=TRUE){
  final_var <- step_on_mice_res[step_on_mice_res > threshold]
  fin_var_name <- names(final_var)
  fin_var_name <- fin_var_name[fin_var_name!= "(Intercept)"]
  if (intercept){
  formula_ <- as.formula(paste("Q", paste(fin_var_name, collapse=" + "), sep=" ~ "))
  } else {
    formula_ <- as.formula(paste("Q", paste(paste(fin_var_name, collapse=" + "), "-1"), sep=" ~ "))
  }
  print(formula_)
  with(data = mice_object, exp=lm(formula(format(formula_))))
}
```

* Dans le cas de la méthode PMM, l'ensemble des variables présentes dans plus de 50% des modèles le sont dans tous, ce sont donc celles que nous retenons pour notre modèle final

```{r}
var_count <- step_on_mice(imputed_pmm)
plot(var_count)
fit_selected_var <- make_linear_model(imputed_pmm, var_count)
summary(pool(fit_selected_var))
```

* Pour la méthode utilisant un modèle linéaire, nous retrouvons les mêmes variables que précédement dans les 10 modèles mais 3 autres apparaissent dans plus de la moitié des cas, sans pour autant être systématiquement présentes. Par ailleurs ces mêmes variables apparaissent peu significatives avec des p-value élevées.

```{r}
var_count <- step_on_mice(imputed_normnob)
plot(var_count)
fit_selected_var <- make_linear_model(imputed_normnob, var_count)
summary(pool(fit_selected_var))
```

Nous réalisons alors des tests afin de vérifier si ces variables sont nécessaires au modèle. Nous testons tout d'abord l'intérêt de la variable A : 

```{r}
fit_without <- with(imputed_normnob, lm(Q ~ AA + D + K + L + M + P + S + T + U))
fit_with <- with(imputed_normnob, lm(Q ~ A + AA + D + K + L + M + P + S + T + U))
anova(fit_with, fit_without)
```

La p-value du test est égale à 0,21, nous considérons donc que A n'est pas nécessaire au modèle. Nous testons maintenant la pertinence de L :

```{r}
fit_without <- with(imputed_normnob, lm(Q ~ AA + D + K + M + P + S + T + U))
fit_with <- with(imputed_normnob, lm(Q ~ AA + D + K + L + M + P + S + T + U))
anova(fit_with, fit_without)
```

La p-value est toujours importante (0,88), nous ne conservons pas la variable L. Enfin nous vérifions la nécessité de conserver AA :

```{r}
fit_without <- with(imputed_normnob, lm(Q ~ D + K + M + P + S + T + U))
fit_with <- with(imputed_normnob, lm(Q ~ AA + D + K + M + P + S + T + U))
anova(fit_with, fit_without)
```

Cette fois ci la p-value est bien meilleure, à 0,08. (CONSERVER OU PAS????)

* Enfin, pour la méthode de Random Forest, nous observons à nouveau des varibles apparaissant plus de 5 fois mais pas à chaque occurence, certaines présentant des p-values élevées :

```{r}
var_count <- step_on_mice(imputed_normnob)
plot(var_count)
fit_selected_var <- make_linear_model(imputed_normnob, var_count)
summary(pool(fit_selected_var))
```

En testant à nouveau le modèle comme précédemment, nous décidons de retirer L et (CONSERVER OU RETIRER les pv autour de 0.08?)

```{r}
fit.without <- with(imputed_rf, lm(Q ~ AA + D + K + M + P + S + T + U))
fit.with <- with(imputed_rf, lm(Q ~ AA + D + K + L + M + P + S + T + U))
anova(fit.with, fit.without)#conserve pas L

fit.without <- with(imputed_rf, lm(Q ~ D + K + M + P + S + T + U))
fit.with <- with(imputed_rf, lm(Q ~ AA + D + K + M + P + S + T + U))
anova(fit.with, fit.without)
```

Au final, avec cette deuxième façon de faire, nous obtenons 3 modèles relativement similaires (A COMPLETER SELON CHOIX DES VARIABLES A CONSERVER), où la fécondité d'un pays dépend positivement de la part de l'agriculture et de la pêche dans le PIB, du taux de mortalité infantile et des termes de l'échange (rapport entre les prix des exportations et les prix des importations). Elle est en revanche négativement affectée par le taux de vaccination infantile à la rubéole (probablement négativement corrélé à la mortalité infantile), l'espérance de vie, les émissions de CO2 et le nombre de souscription à des portables.

Ces résultats semblent assez intuitifs, les pays les plus développés et les plus riches sont réputés pour avoir des taux de fécondité plus faibles. En revanche les variables explicatives selectionnées peuvent avoir de quoi surprendre par rapport à d'autres indicateurs à priori plus directs.