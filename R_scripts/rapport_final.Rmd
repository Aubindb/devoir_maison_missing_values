---
title: "Devoir ACP et valeurs manquantes, Novembre 2018"
author: "Aubin de Belleroche, Camille Moatti"
date: "01 Novembre 2018"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Les données issues du monde réel sont souvent moins faciles à manipuler que celles formatées pour les salles de classe.  
L'analyste doit fréquemment remanier les données afin d'obtenir un enregistrement par ligne et une variable par colonne (*tidy data*) ainsi que reformater les données (paramètres régionaux, formats des dates, codage des catégories...). 
Très souvent, les jeux de données contiennent également des valeurs manquantes. Cela peut-être dû à une multitude de facteurs :

* défaillance matérielle (capteur en panne par exemple)
* nouvelle variable apparue à une certaine date (valeurs manquantes pour les dates antérieures)
* sondage  auxquel les sondés n'ont répondu que partiellement
* individu faisant parti d'une cohorte n'étant plus en mesure de répondre...  

A chaque fois, l'analyste devra déterminer quels sont les raisons de la présence de ces valeurs manquantes avant de trouver une solution pour y remédier.  
Il n'existe malheureusement pas de manière unique de traiter les valeurs manquantes. Plusieurs techniques pourront être essayés afin de trouver la meilleure solution dans un cas donné. Le but de l'imputation est donc de compléter un jeu de données sans changer la structure des données réelles. En effet, une mauvaise imputation ou l'abandon de certaines observations peut conduire à des analyses biasées.

### Présentation du jeu et analyse exploratoire

Nous avons choisi d'analyser un jeu qui provient de la banque mondiale. L'institution financière internationale, dont le rôle est d'accorder des prêts afin d'encourager le développement, dispose d'un site permettant de requêter des données sur l'ensemble des pays. Nous avons choisi d'analyser les indicateurs les plus populaires (*Popular Indicators*). Le détail des variables ainsi que leurs sources sont disponibles dans le fichier `des.xlsx` à la racine du projet.  

Le but final de notre étude sera d'implémenter un modèle pour expliquer et prévoir le nombre d'enfants par femme dans un pays donné.

Nous chargeons les *packages* nécessaires à l'analyse :
  
> Code R masqué.

```{r init, include=F, warning=FALSE, results='hide'}
library("tidyverse")
library("magrittr")

library("FactoMineR")
library("factoextra") #http://www.sthda.com/english/rpkgs/factoextra/

library("missMDA")
library("mice")
library("randomForest")
library("FactoInvestigate")

library("VIM")

library(UpSetR)
library(naniar)
```

Après avoir chargé les données nous en observons la répartition des valeurs manquantes en leur sein.
```{r}
raw_data2 <- readxl::read_xlsx("../data/Popular Indicators.xlsx", na="..") %>% filter(Time==2010)
raw_data2 %>%
  summarise_all(funs(sum(is.na(.)))) / nrow(raw_data2) * 100 -> missing_values_pct
gg_miss_var(raw_data2, show_pct = TRUE)
```

Nous remarquons qu'un certain nombre de variables ont un pourcentage de valeurs manquantes très élevé. Etant donné le peu d'individus présents dans l'échantillon, nous avons considéré que les variables présentant un taux de valeurs manquantes supérieur à 20% ne présentaient pas assez de données pour imputer sans risque d'abimer le modèle. Les colonnes correspondantes ont donc été supprimées.  
Nous abandonnons également les enregistrements sur lesquels notre *target variable* n'a pas de valeur. La variable `data clean` contient donc un `Tible` qui sera utilisé comme point de départ des imputations.
```{r}
missing_values_pct <- missing_values_pct %>% gather() %>% arrange(-value)
inf_20_pct<-missing_values_pct %>% filter(value<=20)
data_limited_missing <- raw_data2 %>% select(inf_20_pct$key)
data_clean <- data_limited_missing %>%
  drop_na(`Fertility rate, total (births per woman) [SP.DYN.TFRT.IN]`)
```

Nous avons également choisi de supprimer les colonnes présentant des mesures de PIB par pays. En effet, nous disposons également du PIB par individu et de la population pour chaque pays, le PIB global n'apporte donc pas plus d'information.

```{r}
data_clean %<>% select(-c(`GNI, PPP (current international $) [NY.GNP.MKTP.PP.CD]`,
                          `GNI, Atlas method (current US$) [NY.GNP.ATLS.CD]`,
                          `GDP (current US$) [NY.GDP.MKTP.CD]`))
```

Afin de faciliter la lecture dans la suite de notre analyse, nous renomons les différentes colonnes par des lettres et conservons la correspondance dans un dictionnaire.

```{r}
saved_names <- names(data_clean)
LETTERS702 <- c(LETTERS, sapply(LETTERS, function(x) paste0(x, LETTERS)))
names(data_clean) <- LETTERS702[1:dim(data_clean)[2]]

letters_dict <- saved_names
names(letters_dict) <- LETTERS702[1:dim(data_clean)[2]]
```

La méthode de l'imputation multiple sera privilégiée tout au long de ce devoir afin de pouvoir estimer l'incertitude associée à notre imputation.  

## Imputation des données manquantes et choix du modèle
### Détermination du mécanisme

Afin de choisir correctement la méthode d'imputation des données manquantes, il convient d'en déterminer le mécanisme. On considère 3 cas possibles (Little & Rubin) :
  
* MCAR (missing completely at random) si probabilité d’absence est la même pour toutes les observations, c'est à dire qu'elle ne dépend que de paramètres extérieurs;
* MAR (missing at random) lorsque la probabilité d’absence est liée à une ou plusieurs autres données observées;
* MNAR (Missing not at random) si les données observées ne suffisent pas à expliquer les données manquantes, c'est à dire que ces dernières dépendent également des données manquantes.

Afin d'analyser la répartition des valeurs manquantes, nous réalisons le graphique suivant à l'aide du package VIM

```{r}
VIM::aggr(data_clean)
```

Nous en déduisons qu'il ne semble pas exister de schéma spécifique de répartion de nos données manquantes. En effet, aucune répartition de ces dernières en fonction des variables n'apparaît avec une fréquence sensiblement supérieure aux autres. En revanche la répartition des valeurs manquantes selon les variables est très inégale, le cas le cas MCAR semble donc exclu dans notre échantillon.

La distinction entre les cas MAR et MNAR n'est ici pas possible sans connaître la façon dont les données ont été collectées. Par défaut nous supposerons un mécanisme MAR et vérifierons la robustesse de ce choix à postériori.


### Imputation et ACP

Dans un premier temps, nous implémentons l'algorithme de l'ACP itératif afin de réaliser une imputation multiple. 
L'explication détaillée de l'algorithme est disponible sur [YouTube](https://www.youtube.com/watch?v=OOM8_FH6_8o).

Le *chunk* suivant permet de régler quelques détails, notamment la conversion en `data.frame` base R et le centrage réduction des données.   
Nous enlevons la variable cible afin d'éviter le **surapprentissage**.
```{r}
data_clean_numeric <- data_clean %>%
  select(which(sapply(.,is.numeric))) %>%
  as.data.frame(.)

# ajout 3/11 : centrage et réduction des données, conseillé avant PCA :
data_clean_numeric <- scale(data_clean_numeric) %>% as.data.frame(.)
# On sort la variable cible :
target <- data_clean_numeric$Q
data_clean_numeric %<>% select(-Q)
```
Puis nous utilisons l'algorithme avec 10 *resampling* via *Parametric Bootstrap (Josse, J., Husson, F. (2010))*:
```{r}
nbdim <- estim_ncpPCA(data_clean_numeric)
res.comp <- MIPCA(data_clean_numeric, ncp = nbdim$ncp, scale=TRUE, nboot = 10)
imp<-prelim(res.comp, data_clean_numeric)
```
la fonction `prelim` permet d'obtenir un objet de type `mids` et d'utiliser les capacités graphiques du package `mice`.
Nous commençons par les graphiques prévus par MissMDA :
```{r, fig.keep='all',fig.show='hold', error=F}
plot(res.comp)
```

Les graphiques montrent que les axes sont stables entre les n imputations. De plus, les valeurs imputées ont une variabilité plutôt limitée. Nous pouvons noter que les variables A et C sont mal représentées.

Puis nous utilisons les fonctions `densityplot` et `stripplot` du *package* `mice` :
```{r}
densityplot(imp)
stripplot(imp, pch = 20, cex = 1.2)
```

Le `stripplot` permet de bien visualiser la stabilité des valeurs imputées (points rouges) d'une imputation à l'autre. En abscisse, les n imputations sont représentées. En ordonnées, nous avons les valeurs imputées. Pour s'assurer de la robustesse de la procédure d'imputation, il faut que les points rouges soient similaires tout au long de l'axe des abscisses. Pour cette raison, les valeurs imputées sur les variables P et U ne sont pas satisfaisantes. Cependant, nous ne les enlevons pas à ce stade.  
  
Afin de continuer vers la modélisation, nous choisissons dans un premier temps de réduire le nombre de dimensions :
```{r}
# Le tableau avec les valeurs imputées est disponible comme ceci :
data_imputed <- res.comp[["res.imputePCA"]]

res<-PCA(data_imputed, graph = F)
# plot(res)
```
Même si la première dimension domine largement les autres, il semble opportun de garder quatre dimensions supplémentaires (72% de variance conservée) :
```{r}
fviz_screeplot(res, addlabels = TRUE, ylim = c(0, 35))
```

```{r}
# Les variables en fonction de leurs contributions :
fviz_pca_var(res, col.var="contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE # Avoid text overlapping
             )
```
  
Hormis les variables A et C, les contributions sont acceptables.
```{r}
# Enlever ce chunk ?
# Les contributions des variables à l'axe 1
fviz_contrib(res, choice = "var", axes = 1, top = 10)
# Les contributions des variables à l'axe 2
fviz_contrib(res, choice = "var", axes = 2, top = 10)
```

La fonction `Investigate(res)` du package `FactoInvestigate` permet de générer un rapport automatisé sur notre ACP. Cette analyse peut servir de point de départ afin d'affiner l'interprétation. 
(A COMPLETER)

Nous pouvons d'ores et déjà visualiser la fertilitité sur les deux premiers axes de notre ACP. Pour ce faire, nous créons trois catégorie à partir de la variable continue cible. Ces trois catégories peuvent être interprétées comme des niveaux du nombre d'enfants par femme (élevé, moyen et faible). Pour ce faire, nous utilisons la fonction `cut` :
```{r}
fviz_pca_ind(res,
             label = "none",
             habillage = cut(target,3),
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE)
```
  
Avec seulement deux dimensions, nous observons qu'un point ayant une valeur positive sur la première dimension appartient presque toujours à la première catégorie (faible fertilité).  
Les deux autres catégories, bien que plus proches, permettent d'observer que les pays où les femmes ont beaucoup d'enfants tendent à avoir une valeur très négative sur la première dimension.  
Le visualisation de la seconde dimension par rapport à la troisième est plus difficile à interpréter de prime abord :

```{r}
fviz_pca_ind(res,
             axes=c(2,3),
             label = "none",
             habillage = cut(target,3),
             palette = c("#00AFBB", "#E7B800", "#FC4E07"),
             addEllipses = TRUE)
```

Notre première modélisation, effectuée après imputation des valeurs manquantes et réduction de la dimension à cinq axes, permet d'obtenir un R ajusté de 78%.

```{r}
# modélisation avec 5 dimensions
ind_coord <- res[["ind"]][["coord"]] %>% as_tibble()
ind_coord_target <- ind_coord %>% mutate(target = target)
fit <- lm(target~.-1, ind_coord_target)
summary(fit)
# plot(fit)
```

### Imputation et Algorithme Mice

L'algorithme utilisé dans le package Mice (**M**ultivariate **I**mputation by **C**hained **E**quations) a été dévelopé par Stef van Buuren. Tout comme l'algorithme implémenté dans MissMDA, dévelopé par François Husson, Mice utilise une approche itérative afin d'imputer les valeurs manquantes. L'approche multiple permet de mesurer l'incertitude quant aux valeurs imputées.  
Afin d'effectuer notre analyse, nous allons utiliser la fonction `mice()` en variant les méthodes d'imputation.  
`mice` est une méthode de Monte Carlo par chaines de Markov qui utilise la structure des corrélations pour trouver des valeurs plausibles sur les jeux incomplets.  
Nous allons essayer trois méthodes :
  
* *Predictive Mean Matching (Rubin 1986, Little 1988)* : Cette méthode est la méthode par défaut de la fonction `mice()`. Cependant, aucune théorie mathématique n'a prouvé la pertinence de cette méthode. Toutefois, cette méthode permet d'imputer avec des valeurs empruntées aux autres observations. Par exemple, sur une colonne d'entiers, *pmm* imputera des entiers. Les valeurs imputées seront contenues entre la borne minimum et maximum de la variable. Ces qualités ont rendu cette méthode assez populaire. [Cet article](https://statisticalhorizons.com/predictive-mean-matching) explique l'algorithme en détail ainsi que ses limites.
* *Linear Regression Ignoring Model Error* : Cette seconde méthode utilise un modèle linéaire afin d'estimer les valeurs manquantes. Cependant, l'algorithme ajoute un bruit gaussien à la prédiction afin d'eviter l'*overfitting*. Mice propose d'autres algorithmes d'imputations s'appuyant sur le modèle linéaire gaussien. [Cette page](https://stefvanbuuren.name/fimd/sec-linearnormal.html) les explique en détail. Nous utiliserons donc `norm.nob`.
* *Random Forest* : Cet algorithme ensembliste est une amélioration de l'arbre de décision simple. Il est utilisé dans le cadre de l'apprentissage statistique afin de réduire la tendance à l'*overfitting* des arbres. Tout comme les arbres, il peut être utilisé pour prédire des variables continues. Ces méthodes sont robustes aux *outliers*, gèrent la multicollinéarité et les distributions assymétriques. Cela est appréciable dans le cadre de l'imputation.
[Cette page](https://stefvanbuuren.name/fimd/sec-cart.html) peut être consultée pour plus de détails.

Tout comme précédemment, nous remanions légèrement notre tableau afin d'assurer sa compatibilité avec `mice`. Grâce à `predictorMatrix`, nous pouvons empêcher la variable `Q` d'être utilisée lors de l'imputation :

```{r}
# Second mode opératoire avec mice. On va utiliser plusieurs méthodes
# offertes par le package afin de compléter les valeurs manquantes
# et de construire un modèle :
data_clean_numeric_mice <- data_clean %>% 
  select(which(sapply(.,is.numeric)))
data_clean_numeric_mice <- scale(data_clean_numeric_mice) %>%
  as.data.frame(.)
# On sort la variable cible. Etant donné le fonctionnement particulier
# de pool, il est difficile d'ajouter une colonne "target" avant le modeling
# comme nous l'avons fait avec missMDA. Cependant, l'utilisation
# du paramètre predictorMatrix nous permet d'exclure une variable
# lors de l'imputation :
imp <- mice(data_clean_numeric_mice, print = FALSE)
pred <- imp$predictorMatrix
pred[, "Q"] <- 0
```

Nous imputons avec les trois méthodes décrites précédemment. Dix imputations sont réalisées pour chaque méthode :
```{r}
#Predictive mean matching
imputed_pmm = mice(data_clean_numeric_mice, pred = pred, method="pmm", m=10)
#Linear regression ignoring model error
imputed_normnob = mice(data_clean_numeric_mice, pred = pred, method="norm.nob", m=10)
#random forest
imputed_rf = mice(data_clean_numeric_mice, pred = pred,method="rf", m=10)
```

